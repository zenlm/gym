\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{cite}

\title{Zen Gym: Unified AI Training Platform}

\author{
    Zen Research Authors \\
    \textit{Zen Research DAO} \\
    \textit{Zoo Labs Inc (501(c)(3) Non-Profit)} \\
    San Francisco, California, USA \\
    \texttt{dev@hanzo.ai} \\
    \texttt{+1 (913) 777-4443}
}

\date{September 2025}

\begin{document}

\maketitle

\begin{abstract}
Comprehensive training platform supporting LoRA, QLoRA, GRPO, GSPO, DPO, PPO and 10+ modern methods.
\end{abstract}

\section{Introduction}
Comprehensive training platform supporting LoRA, QLoRA, GRPO, GSPO, DPO, PPO and 10+ modern methods.

\subsection{Key Features}
\begin{itemize}
    \item Unified interface for 15+ training methods
    \item 2-5x speedup with Unsloth integration
    \item 40-60\% memory reduction with GRPO
    \item Support for 0.6B to 200B+ parameter models
\end{itemize}

\section{Technical Specifications}
\begin{table}[h]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Supported Models & 0.6B - 200B+ parameters \\
Training Methods & 15+ (LoRA, GRPO, DPO, etc.) \\
Optimizations & Unsloth, FlashAttention-2, Liger \\
Distributed & FSDP, DeepSpeed, Multi-node \\
Hardware & Single GPU to multi-node clusters
\bottomrule
\end{tabular}
\caption{Technical specifications}
\label{tab:specs}
\end{table}

\section{Zen AI Ecosystem}

This is part of the complete Zen AI hypermodal ecosystem:

\textbf{Language Models}: zen-nano-0.6b, zen-eco-4b-instruct, zen-eco-4b-thinking, zen-agent-4b

\textbf{3D \& World}: zen-3d, zen-voyager, zen-world

\textbf{Video}: zen-director-5b, zen-video, zen-video-i2v

\textbf{Audio}: zen-musician-7b, zen-foley

\textbf{Infrastructure}: Zen Gym (training), Zen Engine (inference)

\section{Conclusion}
Zen Gym unifies modern AI training methods in a single platform, achieving 2-5x speedup and 40-60\% memory reduction.

\section*{Acknowledgments}
We thank the open-source community and our upstream contributors.

\bibliographystyle{plain}
\bibliography{paper}

\end{document}
